{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "data = load_dataset('Diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('price', axis = 1)\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0  4.34  4.35  2.75"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 9 columns):\n",
      "carat      53940 non-null float64\n",
      "cut        53940 non-null object\n",
      "color      53940 non-null object\n",
      "clarity    53940 non-null object\n",
      "depth      53940 non-null float64\n",
      "table      53940 non-null float64\n",
      "x          53940 non-null float64\n",
      "y          53940 non-null float64\n",
      "z          53940 non-null float64\n",
      "dtypes: float64(6), object(3)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table             x             y  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184      5.731157      5.734526   \n",
       "std        0.474011      1.432621      2.234491      1.121761      1.142135   \n",
       "min        0.200000     43.000000     43.000000      0.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000      4.710000      4.720000   \n",
       "50%        0.700000     61.800000     57.000000      5.700000      5.710000   \n",
       "75%        1.040000     62.500000     59.000000      6.540000      6.540000   \n",
       "max        5.010000     79.000000     95.000000     10.740000     58.900000   \n",
       "\n",
       "                  z  \n",
       "count  53940.000000  \n",
       "mean       3.538734  \n",
       "std        0.705699  \n",
       "min        0.000000  \n",
       "25%        2.910000  \n",
       "50%        3.530000  \n",
       "75%        4.040000  \n",
       "max       31.800000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0  4.34  4.35  2.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ideal', 'Premium', 'Good', 'Very Good', 'Fair'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['cut'].unique() #map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E', 'I', 'J', 'H', 'F', 'G', 'D'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['color'].unique() #one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SI2', 'SI1', 'VS1', 'VS2', 'VVS2', 'VVS1', 'I1', 'IF'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['clarity'].unique() #map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cut'] = X['cut'].map({'Ideal':4, 'Premium':3, 'Good':1, 'Very Good':2, 'Fair':0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['clarity'] = X['clarity'].map({'SI2':1, 'SI1':2, 'VS1':4, 'VS2':3, 'VVS2':5, 'VVS1':6, 'I1':0, 'IF':7}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = pd.get_dummies(X['color'])\n",
    "X[cols.columns] = cols\n",
    "X.drop('color', inplace=True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut  clarity  depth  table     x     y     z  D  E  F  G  H  I  J\n",
       "0   0.23    4        1   61.5   55.0  3.95  3.98  2.43  0  1  0  0  0  0  0\n",
       "1   0.21    3        2   59.8   61.0  3.89  3.84  2.31  0  1  0  0  0  0  0\n",
       "2   0.23    1        4   56.9   65.0  4.05  4.07  2.31  0  1  0  0  0  0  0\n",
       "3   0.29    3        3   62.4   58.0  4.20  4.23  2.63  0  0  0  0  0  1  0\n",
       "4   0.31    1        1   63.3   58.0  4.34  4.35  2.75  0  0  0  0  0  0  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    326\n",
       "1    326\n",
       "2    327\n",
       "3    334\n",
       "4    335\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models\n",
    "\n",
    "1. Linear regression \n",
    "2. KNN regrssor - best param\n",
    "3. SGDRegressor - best params\n",
    "4. Ridge - best param\n",
    "5. Lasso - feature importance, best param\n",
    "6. LinearSVR - best param\n",
    "7. SVR kernel = 'rbf' and 'poly' - best params\n",
    "8. Decision Tree Regressor - best params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype uint8, int32, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int32, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#scale dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train_org)\n",
    "scaler.fit(X_train_org)\n",
    "X_train = scaler.transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('diamond_BUAN002.csv', 'w')\n",
    "line  = 'Model_name,Model_params,Train_score,Test_score\\n'\n",
    "f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9091\n",
      "Test score: 0.9103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "lreg.fit(X_train, y_train)\n",
    "\n",
    "print('Train score: %.4f'%lreg.score(X_train, y_train))\n",
    "print('Test score: %.4f'%lreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = 'LinearRegression, ,' + str(lreg.score(X_train, y_train)) + ',' + str(lreg.score(X_test, y_test)) + '\\n'\n",
    "f = open('diamond_BUAN002.csv','a')\n",
    "f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot - based on only one feature in the X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- KNN Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for k in [1, 3, 5, 7, 9]:\n",
    "    #create the model\n",
    "    knn = KNeighborsRegressor(n_neighbors= k)\n",
    "    # train the model on the train set\n",
    "    knn.fit(X_train, y_train)\n",
    "    train.append(knn.score(X_train, y_train))\n",
    "    test.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'n_neighbors')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([1, 3, 5, 7, 9], train, label = 'Train score')\n",
    "plt.plot([1, 3, 5, 7, 9], test, label = 'Test score')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter is ``n_neighbors = 5``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('diamond_BUAN002.csv', 'a')\n",
    "line = 'KNeighborsRegressor, n_neighbors = 5, ' + str(train[2]) + ',' + str(test[2]) + '\\n'\n",
    "f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- SGDRegressor\n",
    "\n",
    "- ``max_iter in [1000, 5000, 10000]``\n",
    "- ``penalty in ['l1', 'l2']``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6176270de2d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msgd_l1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0msgd_l2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1260\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m                          \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1262\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate,\n\u001b[0;32m   1221\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m                           intercept_init)\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m         if (self._tol is not None and self._tol > -np.inf\n",
      "\u001b[1;32mc:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m         self._fit_regressor(X, y, alpha, C, loss, learning_rate,\n\u001b[1;32m-> 1164\u001b[1;33m                             sample_weight, max_iter)\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nxs045000\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_regressor\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                           \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                           intercept_decay)\n\u001b[0m\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "train_l1 = []\n",
    "test_l1 = []\n",
    "train_l2 = []\n",
    "test_l2 = []\n",
    "\n",
    "for max_iter in [1000, 5000, 10000]:\n",
    "    #create the model\n",
    "    sgd_l1 = SGDRegressor(max_iter = max_iter, penalty= 'l1')\n",
    "    sgd_l2 = SGDRegressor(max_iter = max_iter, penalty= 'l2')\n",
    "    \n",
    "    #train the model\n",
    "    sgd_l1.fit(X_train, y_train)\n",
    "    sgd_l2.fit(X_train, y_train)\n",
    "    \n",
    "    #evaluation\n",
    "    train_l1.append(sgd_l1.score(X_train, y_train))\n",
    "    test_l1.append(sgd_l1.score(X_test, y_test))\n",
    "    train_l2.append(sgd_l2.score(X_train, y_train))\n",
    "    test_l2.append(sgd_l2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "plt.plot([1000, 5000, 10000], train_l1 , label = 'Train score - l1')\n",
    "plt.plot([1000, 5000, 10000], test_l1 , label = 'Test score - l1')\n",
    "plt.plot([1000, 5000, 10000], train_l2 , label = 'Train score - l2')\n",
    "plt.plot([1000, 5000, 10000], test_l2 , label = 'Test score - l2')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('max_iter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#base model\n",
    "sgd = SGDRegressor(random_state = 0)\n",
    "\n",
    "#grid params\n",
    "grid_param = {'penalty': ['l1', 'l2'], \n",
    "             'max_iter':[1000, 5000, 10000]}\n",
    "\n",
    "#build the grid earch model\n",
    "sgd_grid = GridSearchCV(sgd, grid_param, cv = 7, return_train_score = True, n_jobs= -1)\n",
    "\n",
    "#train the model\n",
    "sgd_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_grid.cv_results_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('diamond_BUAN002.csv', 'a')\n",
    "line = 'SGDRegressor, penalty = l1 - max_iter = 5000, ' + str(train_l1[1]) + ',' + str(test_l1[1]) + '\\n'\n",
    "f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "train = []\n",
    "test= []\n",
    "\n",
    "for alpha in [0.01, 0.1, 1, 10, 100]: \n",
    "    #create the model \n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #train the model\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    #evalutation\n",
    "    train.append(ridge.score(X_train,y_train))\n",
    "    test.append(ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot([0.01, 0.1, 1, 10, 100], train, label = 'Train score')\n",
    "plt.plot([0.01, 0.1, 1, 10, 100], test, label = 'Test score')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('diamond_BUAN002.csv', 'a')\n",
    "line = 'Ridge, alpha = 0.01, ' + str(train[0]) + ',' + str(test[0]) + '\\n'\n",
    "f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('diamond_BUAN002.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-DecisionTreeRegressor()\n",
    "use grid search to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#base model\n",
    "tree = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "#model params\n",
    "grid_param = {'max_depth':[1, 2, 3, 5, 9, 15]}\n",
    "\n",
    "#build the grid search model\n",
    "tree_grid = GridSearchCV(tree, grid_param, cv = 5, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "#train the model\n",
    "tree_grid.fit(X_train, y_train)\n",
    "\n",
    "#get the results \n",
    "print('Best score:', tree_gird.best_score_)\n",
    "print('Best param:', tree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Bagging Regressor with Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensmble import BaggingRegressor\n",
    "\n",
    "#base model\n",
    "tree = DecisionTreeRegressor(random_state = 0)\n",
    "\n",
    "#Build the bagging regressor model\n",
    "bag_reg = BaggingRegressor(tree, n_estimators = 100, max_samples = 500, \n",
    "                           max_features = 5, bootstrap = True, oob_score = True)\n",
    "\n",
    "#train the model\n",
    "bag_reg.fit(X, y)\n",
    "\n",
    "#model attributes\n",
    "print(bag_reg.oob_score_)\n",
    "print(bag_reg.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40455, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 13944917.9714 - mse: 13944919.0000\n",
      "Epoch 2/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 5083658.8982 - mse: 5083659.0000\n",
      "Epoch 3/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 3038740.9304 - mse: 3038740.5000\n",
      "Epoch 4/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 2173458.3077 - mse: 2173458.5000\n",
      "Epoch 5/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 2305947.2117 - mse: 2305947.7500\n",
      "Epoch 6/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1745956.6223 - mse: 1745956.5000\n",
      "Epoch 7/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1577052.6953 - mse: 1577052.2500\n",
      "Epoch 8/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1417054.7443 - mse: 1417054.0000\n",
      "Epoch 9/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1354056.5941 - mse: 1354056.8750\n",
      "Epoch 10/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1254278.6690 - mse: 1254278.8750\n",
      "Epoch 11/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1191512.1032 - mse: 1191511.7500\n",
      "Epoch 12/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1132955.9103 - mse: 1132956.1250\n",
      "Epoch 13/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1125206.6213 - mse: 1125206.3750\n",
      "Epoch 14/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1072493.2636 - mse: 1072493.2500\n",
      "Epoch 15/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1031003.8004 - mse: 1031003.6250\n",
      "Epoch 16/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1058213.2049 - mse: 1058213.5000\n",
      "Epoch 17/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1086232.4653 - mse: 1086232.2500\n",
      "Epoch 18/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1158967.2462 - mse: 1158967.3750\n",
      "Epoch 19/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1048116.1379 - mse: 1048116.3125\n",
      "Epoch 20/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1211361.1146 - mse: 1211361.1250\n",
      "Epoch 21/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1059512.3611 - mse: 1059512.2500\n",
      "Epoch 22/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1037910.9652 - mse: 1037911.1875\n",
      "Epoch 23/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1048608.8702 - mse: 1048608.6250\n",
      "Epoch 24/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 959736.3600 - mse: 959736.3125\n",
      "Epoch 25/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 989745.6838 - mse: 989745.5625\n",
      "Epoch 26/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 967814.3970 - mse: 967814.2500\n",
      "Epoch 27/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 945735.3064 - mse: 945735.0625\n",
      "Epoch 28/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 929555.3892 - mse: 929555.8125\n",
      "Epoch 29/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1026296.3260 - mse: 1026296.1875\n",
      "Epoch 30/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1034218.4133 - mse: 1034218.5000\n",
      "Epoch 31/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 929595.1503 - mse: 929595.1875\n",
      "Epoch 32/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 906130.7808 - mse: 906130.7500\n",
      "Epoch 33/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 933037.9027 - mse: 933037.9375\n",
      "Epoch 34/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 911561.2019 - mse: 911561.2500\n",
      "Epoch 35/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 939232.2947 - mse: 939232.3125\n",
      "Epoch 36/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 957062.9135 - mse: 957062.7500\n",
      "Epoch 37/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 991230.7542 - mse: 991231.0000\n",
      "Epoch 38/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 896775.5947 - mse: 896775.3125\n",
      "Epoch 39/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 944029.4363 - mse: 944029.6250\n",
      "Epoch 40/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 928637.6236 - mse: 928637.3750\n",
      "Epoch 41/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 872009.4656 - mse: 872009.5000\n",
      "Epoch 42/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 882812.3596 - mse: 882812.3750\n",
      "Epoch 43/50\n",
      "40455/40455 [==============================] - 0s 4us/sample - loss: 927642.1419 - mse: 927642.0625\n",
      "Epoch 44/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1000800.6309 - mse: 1000800.5000\n",
      "Epoch 45/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1085802.9283 - mse: 1085803.0000\n",
      "Epoch 46/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1067921.7607 - mse: 1067921.6250\n",
      "Epoch 47/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 1030612.3696 - mse: 1030612.4375\n",
      "Epoch 48/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 997102.9554 - mse: 997103.3125\n",
      "Epoch 49/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 964559.2369 - mse: 964559.4375\n",
      "Epoch 50/50\n",
      "40455/40455 [==============================] - 0s 3us/sample - loss: 968877.3407 - mse: 968877.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c3ffb38>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 1: build the model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 15, activation = 'sigmoid'))\n",
    "#hidden layer\n",
    "#output layer: no activation function\n",
    "model1.add(Dense(1))\n",
    "\n",
    "#step 2: compile the model\n",
    "model1.compile(loss = 'mse', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "#step 3: train the model\n",
    "model1.fit(X_train,y_train, epochs = 20, batch_size = 256)\n",
    "\n",
    "#step 4: model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455/40455 [==============================] - 0s 12us/sample - loss: 934281.6544 - mse: 934282.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[934281.6543918398, 934282.4]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13485/13485 [==============================] - 0s 11us/sample - loss: 945625.9098 - mse: 945626.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[945625.9097677976, 945626.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = model1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387692172698264"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred =  y_train_pred.reshape(-1,1)\n",
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9407928014414323"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
